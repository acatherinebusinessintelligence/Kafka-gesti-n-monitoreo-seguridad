<!doctype html>
<html lang="es">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PostgreSQL con Podman Compose · Integración con Kafka Connect</title>
<style>
:root{--bg:#ffffff;--paper:#f8fafc;--ink:#0b1220;--muted:#475569;--accent:#0b1220;--border:#e2e8f0;--ok:#059669;--warn:#ca8a04;--err:#dc2626}
*{box-sizing:border-box}
body{margin:0;font-family:Inter,Segoe UI,Roboto,Arial,sans-serif;background:var(--bg);color:var(--ink);line-height:1.7}
.wrap{max-width:1100px;margin:24px auto 64px;padding:0 18px}
h1{font-size:clamp(26px,3.6vw,42px);margin:6px 0 2px;color:var(--accent)}
.lead{color:#334155;margin:0 0 14px}
.card{background:var(--paper);border:1px solid var(--border);border-radius:14px;padding:18px;margin:16px 0;box-shadow:0 2px 8px rgba(0,0,0,.04)}
h2{margin:6px 0 12px;font-size:22px;border-left:4px solid var(--accent);padding-left:10px}
h3{margin:16px 0 8px;font-size:18px}
p{margin:8px 0} ul{margin:8px 0 8px 20px}
pre{background:#fff;border:1px solid var(--border);border-radius:10px;padding:12px;overflow:auto;position:relative}
.copy{position:absolute;right:8px;top:8px;font-size:12px;border:1px solid var(--border);background:#fff;border-radius:8px;padding:3px 8px;cursor:pointer;color:#334155}
.badge{display:inline-block;border:1px solid var(--border);border-radius:999px;padding:4px 10px;margin:2px 6px 0 0;color:#475569;background:#fff;font-size:.85rem}
.note{background:#eef2ff;border-left:3px solid #1d4ed8;border-radius:8px;padding:10px 12px}
.warn{background:#fffbeb;border-left:3px solid var(--warn);border-radius:8px;padding:10px 12px}
.err{background:#fff1f2;border-left:3px solid var(--err);border-radius:8px;padding:10px 12px}
a.button{display:inline-block;text-decoration:none;background:#111827;color:#fff;border-radius:10px;padding:10px 14px;margin:6px 0}
code,kbd{font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,monospace;font-size:13px}
footer{text-align:center;color:#64748b;margin-top:24px;font-size:12px}
</style>
</head>
<body>
<div class="wrap">
  <h1>PostgreSQL con Podman Compose</h1>
  <p class="lead">Integración con <b>Kafka Connect (JDBC Sink)</b> — guía paso a paso.</p>
  <div>
    <span class="badge">Podman</span>
    <span class="badge">PostgreSQL</span>
    <span class="badge">Kafka Connect</span>
    <span class="badge">WSL2</span>
  </div>

  <section class="card">
    <h2>¿Cómo encaja con Kafka?</h2>
    <p>El flujo es: <b>Topic Kafka</b> → <b>Kafka Connect (JDBC Sink)</b> → <b>PostgreSQL</b>. El conector lee mensajes del tópico y escribe filas en la base. Como es una BD relacional, el conector necesita tipos; por eso usamos mensajes <b>con esquema</b> (JSON con <code>schema</code>/<code>payload</code>) o Avro/Protobuf.</p>
<pre><button class="copy">Copiar</button><code>[ productores ]  --->  (topic: orders_schema)  --->  [ Kafka Connect - JDBC Sink ]  --->  [ PostgreSQL: tabla orders ]</code></pre>
    <p class="note"><b>Prerrequisitos:</b> clúster Kafka arriba (<code>zookeeper</code>, <code>kafka1</code>, <code>kafka2</code>, <code>kafka3</code>) y todos en la misma red (normalmente <code>kafka-lab_default</code>).</p>
<pre><button class="copy">Copiar</button><code>podman ps --format "{{.Names}}  {{.Networks}}  {{.Status}}"
# Descubrir el nombre real de la red tomando el zookeeper
NET=$(podman inspect zookeeper -f '{{range $k,$v := .NetworkSettings.Networks}}{{$k}}{{end}}')
echo "$NET"   # debería ser kafka-lab_default</code></pre>
  </section>

  <section class="card">
    <h2>1) Crear el archivo <code>podman-compose-postgres.yml</code></h2>
    <p>Guárdalo en tu carpeta del laboratorio. Usa la <b>misma red</b> externa del clúster (<code>kafka-lab_default</code>).</p>
<pre><button class="copy">Copiar</button><code>version: "3.8"

services:
  postgres:
    image: docker.io/library/postgres:15
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_DB: demo
      POSTGRES_USER: demo
      POSTGRES_PASSWORD: demo
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
      # Descomenta para crear objetos la primera vez:
      # - ./initdb:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kafka-lab_default

  # (Opcional) UI web para administrar Postgres
  pgadmin:
    image: docker.io/dpage/pgadmin4:8.10
    container_name: pgadmin
    hostname: pgadmin
    depends_on:
      - postgres
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin123
    ports:
      - "8081:80"
    networks:
      - kafka-lab_default

networks:
  kafka-lab_default:
    external: true</code></pre>
    <p class="warn"><b>Nota:</b> La red externa debe existir. Si no existe, créala: <code>podman network create kafka-lab_default</code>.</p>
  </section>

  <section class="card">
    <h2>2) Levantar Postgres (+pgAdmin opcional)</h2>
<pre><button class="copy">Copiar</button><code># Sólo la base de datos
podman-compose -f podman-compose-postgres.yml -p kafka-lab up -d postgres

# Con pgAdmin también
podman-compose -f podman-compose-postgres.yml -p kafka-lab up -d pgadmin

# Verifica
podman ps --format "{{.Names}}  {{.Networks}}  {{.Status}}  {{.Ports}}"</code></pre>
    <p>pgAdmin queda en <code>http://localhost:8081</code> (usuario <code>admin@example.com</code> / clave <code>admin123</code>). Registra el servidor:</p>
    <ul>
      <li><b>Host</b>: <code>postgres</code> (si pgAdmin está en contenedor) o <code>localhost</code> (si accedes desde el host).</li>
      <li><b>Port</b>: <code>5432</code> · <b>DB</b>: <code>demo</code> · <b>User</b>: <code>demo</code> · <b>Pass</b>: <code>demo</code>.</li>
    </ul>
  </section>

  <section class="card">
    <h2>3) Probar conectividad desde Kafka</h2>
<pre><button class="copy">Copiar</button><code>podman exec -it kafka1 bash -lc 'getent hosts postgres || echo NO-RESUELVE'
# Debe devolver la IP del contenedor postgres dentro de la red del lab</code></pre>
  </section>

  <section class="card">
    <h2>4) Preparar Kafka Connect</h2>
    <h3>4.1 Instalar plugin JDBC</h3>
<pre><button class="copy">Copiar</button><code>podman exec -it connect bash -lc 'confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:latest && \
  (grep -q "^plugin.path=" /etc/kafka/connect-distributed.properties || \
   echo "plugin.path=/usr/share/java,/usr/share/confluent-hub-components" >> /etc/kafka/connect-distributed.properties)'
podman restart connect
curl -s http://localhost:8083/connector-plugins | grep -i jdbc</code></pre>
    <h3>4.2 Driver JDBC de Postgres</h3>
<pre><button class="copy">Copiar</button><code>podman exec -it connect bash -lc 'cd /usr/share/confluent-hub-components/confluentinc-kafka-connect-jdbc/lib && \
  (ls -1 | grep -i postgresql- || curl -LO https://jdbc.postgresql.org/download/postgresql-42.7.4.jar)'
podman restart connect</code></pre>
  </section>

  <section class="card">
    <h2>5) Tópico de entrada y mensajes <i>con esquema</i></h2>
<pre><button class="copy">Copiar</button><code>podman exec -it kafka1 bash -lc \
  "kafka-topics --create --if-not-exists --topic orders_schema \
   --partitions 3 --replication-factor 3 --bootstrap-server kafka1:29092"

# Enviar 3 eventos válidos (JSON con schema/payload)
cat > orders_schema.jsonl <<'JSONL'
{"schema":{"type":"struct","name":"orders_value","optional":false,"fields":[
  {"field":"order_id","type":"int32","optional":false},
  {"field":"customer","type":"string","optional":false},
  {"field":"amount","type":"double","optional":false}
]},"payload":{"order_id":1001,"customer":"ana","amount":59.9}}
{"schema":{"type":"struct","name":"orders_value","optional":false,"fields":[
  {"field":"order_id","type":"int32","optional":false},
  {"field":"customer","type":"string","optional":false},
  {"field":"amount","type":"double","optional":false}
]},"payload":{"order_id":1002,"customer":"luis","amount":120.0}}
{"schema":{"type":"struct","name":"orders_value","optional":false,"fields":[
  {"field":"order_id","type":"int32","optional":false},
  {"field":"customer","type":"string","optional":false},
  {"field":"amount","type":"double","optional":false}
]},"payload":{"order_id":1003,"customer":"eva","amount":18.5}}
JSONL

cat orders_schema.jsonl | podman exec -i kafka1 bash -lc \
  "kafka-console-producer --bootstrap-server kafka1:29092 --topic orders_schema"</code></pre>
    <p class="warn">Si antes se enviaron mensajes truncados, borra y recrea el tópico antes de producir de nuevo.</p>
  </section>

  <section class="card">
    <h2>6) Crear/Actualizar el JDBC Sink</h2>
<pre><button class="copy">Copiar</button><code># Crear (o actualizar con PUT) el conector
curl -sS -X PUT http://localhost:8083/connectors/jdbc-sink-orders/config \
  -H 'Content-Type: application/json' \
  --data-binary @- <<'JSON'
{
  "name": "jdbc-sink-orders",
  "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
  "tasks.max": "1",
  "topics": "orders_schema",
  "connection.url": "jdbc:postgresql://postgres:5432/demo",
  "connection.user": "demo",
  "connection.password": "demo",
  "auto.create": "true",
  "auto.evolve": "true",
  "insert.mode": "upsert",
  "pk.mode": "record_value",
  "pk.fields": "order_id",
  "value.converter": "org.apache.kafka.connect.json.JsonConverter",
  "value.converter.schemas.enable": "true",
  "key.converter": "org.apache.kafka.connect.storage.StringConverter",
  "errors.tolerance": "all",
  "errors.log.enable": "true",
  "errors.log.include.messages": "true",
  "errors.deadletterqueue.topic.name": "dlq.orders_schema",
  "errors.deadletterqueue.context.headers.enable": "true",
  "errors.deadletterqueue.topic.replication.factor": "3"
}
JSON

# Estado
curl -sS http://localhost:8083/connectors/jdbc-sink-orders/status</code></pre>
  </section>

  <section class="card">
    <h2>7) Verificar en Postgres</h2>
<pre><button class="copy">Copiar</button><code>podman exec -it postgres bash -lc \
  'psql -U demo -d demo -h localhost -c "SELECT * FROM orders ORDER BY order_id;"'</code></pre>
    <p>Si no aparece la tabla <code>orders</code>, revisa el estado del conector y los logs.</p>
<pre><button class="copy">Copiar</button><code>podman logs -f --tail=200 connect</code></pre>
  </section>

  <section class="card">
    <h2>8) Problemas comunes</h2>
    <ul>
      <li><b>Driver faltante</b>: “No suitable driver for jdbc:postgresql” → instala el JAR y reinicia Connect.</li>
      <li><b>Mensajes sin esquema</b>: “non-null Struct schema” → usa JSON con <code>schema/payload</code> o Avro/Protobuf.</li>
      <li><b>Mensaje truncado</b>: <code>JsonEOFException</code> → recrea el tópico y produce desde archivo.</li>
      <li><b>Red</b>: <code>NO-RESUELVE</code> → conecta los contenedores a la misma red del lab.</li>
      <li><b>Credenciales</b>: “password authentication failed” → verifica user/clave y que la DB exista.</li>
    </ul>
  </section>

  <section class="card">
    <h2>9) Limpieza</h2>
<pre><button class="copy">Copiar</button><code># Parar servicios
podman-compose -f podman-compose-postgres.yml -p kafka-lab down

# (opcional) borrar datos persistidos
rm -rf ./pgdata</code></pre>
  </section>

  <footer>Guía — PostgreSQL con Podman Compose para Kafka Connect</footer>
</div>
<script>
document.querySelectorAll('pre').forEach(p=>{
  const b=p.querySelector('.copy'); if(!b) return;
  b.addEventListener('click',async()=>{
    const t=p.querySelector('code').innerText;
    try{
      await navigator.clipboard.writeText(t);
      const old=b.textContent; b.textContent='¡Copiado!'; setTimeout(()=>b.textContent=old,1200);
    }catch(e){ alert('No se pudo copiar'); }
  });
});
</script>
</body>
</html>
